{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ffd369c-af30-4d88-a236-12ddd2e03f92",
   "metadata": {},
   "source": [
    "GradScaler是PyTorch中用于自动混合精度训练的一个重要组件。它通过动态调整梯度的缩放因子来解决在使用半精度（float16）进行训练时可能出现的数值不稳定性问题。为了验证GradScaler的功能和性能，编写一些测试用例（test case）是非常有用的。以下是一个简单的GradScaler测试用例的示例，它将展示如何使用GradScaler进行模型训练，并验证其是否正常工作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c698c60f-226c-4df5-9acb-6dbb153bc986",
   "metadata": {},
   "source": [
    "# GradScaler测试用例\n",
    "\n",
    "## 1. 测试目的\n",
    "验证GradScaler是否能够正确地缩放和调整梯度，以及是否能够在训练过程中保持模型的收敛性。\n",
    "\n",
    "## 2. 测试环境\n",
    "- PyTorch版本：1.6及以上（因为从1.6版本开始内置了`torch.cuda.amp`）\n",
    "- GPU环境：支持CUDA的NVIDIA GPU\n",
    "\n",
    "## 3. 测试步骤\n",
    "\n",
    "### 3.1 准备测试数据和模型\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# 定义一个简单的神经网络模型\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# 创建模型和优化器\n",
    "model = SimpleNet().cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a665d52-772e-4b88-8073-257fab4f6186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import Dataset, DataLoader, DistributedSampler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "class ToyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ToyModel, self).__init__()\n",
    "        self.linear = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class ToyDataset(Dataset):\n",
    "    def __len__(self):\n",
    "        return 100\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.rand(10), torch.rand(10)\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    # os.environ['MASTER_ADDR'] = '172.17.0.2'\n",
    "    # os.environ['MASTER_PORT'] = '50574'\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "    \n",
    "\n",
    "def train(rank, world_size):\n",
    "\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    model = ToyModel().to(rank)\n",
    "    ddp_model = DDP(model, device_ids=[rank])\n",
    "\n",
    "    dataset = ToyDataset()\n",
    "    sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)\n",
    "    dataloader = DataLoader(dataset, sampler=sampler, batch_size=10)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n",
    "\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "        for i, (inputs, labels) in enumerate(dataloader):\n",
    "            inputs = inputs.to(rank)\n",
    "            labels = labels.to(rank)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                outputs = ddp_model(inputs.cuda())\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "            # 缩放损失并进行反向传播\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # 更新梯度\n",
    "            scaler.step(optimizer)\n",
    "\n",
    "            # 更新GradScaler的缩放因子\n",
    "            scaler.update()\n",
    "            print(f\"rank: {rank}, epoch: {epoch}, iteration:{i}, loss: {loss.item():.3f}\")\n",
    "\n",
    "    cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91de011b-5265-4c4f-b62a-bd866fb7ad39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank: 0, epoch: 0, iteration:0, loss: 0.553\n",
      "rank: 0, epoch: 0, iteration:1, loss: 0.476\n",
      "rank: 0, epoch: 0, iteration:2, loss: 0.507\n",
      "rank: 0, epoch: 0, iteration:3, loss: 0.553\n",
      "rank: 0, epoch: 0, iteration:4, loss: 0.479\n",
      "rank: 0, epoch: 0, iteration:5, loss: 0.491\n",
      "rank: 0, epoch: 0, iteration:6, loss: 0.501\n",
      "rank: 0, epoch: 0, iteration:7, loss: 0.421\n",
      "rank: 0, epoch: 0, iteration:8, loss: 0.542\n",
      "rank: 0, epoch: 0, iteration:9, loss: 0.487\n",
      "rank: 0, epoch: 1, iteration:0, loss: 0.420\n",
      "rank: 0, epoch: 1, iteration:1, loss: 0.482\n",
      "rank: 0, epoch: 1, iteration:2, loss: 0.434\n",
      "rank: 0, epoch: 1, iteration:3, loss: 0.510\n",
      "rank: 0, epoch: 1, iteration:4, loss: 0.545\n",
      "rank: 0, epoch: 1, iteration:5, loss: 0.468\n",
      "rank: 0, epoch: 1, iteration:6, loss: 0.414\n",
      "rank: 0, epoch: 1, iteration:7, loss: 0.491\n",
      "rank: 0, epoch: 1, iteration:8, loss: 0.444\n",
      "rank: 0, epoch: 1, iteration:9, loss: 0.454\n"
     ]
    }
   ],
   "source": [
    "os.environ['MASTER_ADDR'] = '172.17.0.2'\n",
    "os.environ['MASTER_PORT'] = '50574'\n",
    "os.environ['RANK'] = '0'\n",
    "os.environ['WORLD_SIZE'] = '1'\n",
    "rank = int(os.environ['RANK'])\n",
    "world_size = int(os.environ['WORLD_SIZE'])\n",
    "train(rank, world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935521b6-263e-49a1-9730-eb75aa8b8229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava_py3",
   "language": "python",
   "name": "llava"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
